{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba2dca2-94ae-4038-b5c2-75c7d9d88212",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7858f-de59-4152-a298-7b3c08972875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import h5py\n",
    "tc.set_default_dtype(tc.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16e609-2458-47fb-b654-88dfb7c7d66a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bac1be-da06-43d2-908f-b4892cfd8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path: str):\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def normalize_field_known_values(F, ma, mi):\n",
    "    for count in range(len(ma)):\n",
    "        F[:,:,count,...] = (F[:,:,count,...]-mi[count])/(ma[count]-mi[count])\n",
    "    return F\n",
    "\n",
    "def normalize_field_known_values_param(F, ma,mi):\n",
    "    return (F-mi)/(ma-mi)\n",
    "\n",
    "def inverse_normalization_field(F,ma,mi, spatial_dimensions): #here one less dimension because the dimension 1 is squeezed in that part of the code\n",
    "    if spatial_dimensions == 1:\n",
    "        for count in range(len(ma)):\n",
    "            F[...,count,:] = F[...,count,:]*(ma[count]-mi[count]) + mi[count]\n",
    "        return F\n",
    "    elif spatial_dimensions == 2:\n",
    "        for count in range(len(ma)):\n",
    "            F[...,count,:,:] = F[...,count,:,:]*(ma[count]-mi[count]) + mi[count]\n",
    "        return F\n",
    "\n",
    "def molenkeamp(X,Y, param, t):\n",
    "    h = np.sqrt((X-param[3]+0.5*np.cos(2*np.pi*t))**2+(Y-param[4]+0.5*np.sin(2*np.pi*t))**2)\n",
    "    \n",
    "    return param[0]*0.01**(param[1]*h**2)*np.exp(-param[2]*t)\n",
    "\n",
    "def get_diff_time_from_dataset(path, skipping_index):\n",
    "    file = h5py.File(path+'/2D_rdb_NA_NA.h5', 'r')\n",
    "    keys = file.keys()\n",
    "    data = file['0212']['grid']\n",
    "    T = []\n",
    "    for t in data['t'][::skipping_index]:\n",
    "        T.append(t)\n",
    "\n",
    "    out = [] \n",
    "    for i in list(keys)[900:]:\n",
    "        data = file[i]['data'][::skipping_index]\n",
    "        out.append(np.reshape(data,(np.shape(data)[0],128,128)))\n",
    "    return np.array(out), T\n",
    "    \n",
    "class CustomStarDataset(Dataset):\n",
    "    # This loads the data and converts it, make data rdy\n",
    "    def __init__(self,file_path_ic,file_path_parameter ):\n",
    "        self.ic = tc.tensor(np.load(file_path_ic), dtype = tc.float32)\n",
    "        self.params = tc.tensor(np.load(file_path_parameter), dtype = tc.float32)\n",
    "        \n",
    "    \n",
    "    # This returns the total amount of samples in your Dataset\n",
    "    def __len__(self):\n",
    "        return len(self.ic)\n",
    "    \n",
    "    # This returns given an index the i-th sample and label\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ic[idx],self.params[idx]\n",
    "def advection(x,mu,t):\n",
    "    length = len(x)\n",
    "    advected = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if i/length < mu*t:\n",
    "            advected[i] = x[0]\n",
    "        else:\n",
    "            advected[i] = x[int(i-mu*t*length)]\n",
    "    return advected\n",
    "\n",
    "def processor_First_Order(f, e1,dt, mu, k, RK, ma_mi, device, time_dependence_in_f):\n",
    "    \"\"\"this function implements the Runge-Kutta algorithms. First_Order refers to the fact that the ODE is a first order ODE, although higher orders would still be solved by this algorithms\n",
    "    simply introducing new functions.\n",
    "\n",
    "    Args:\n",
    "        f (src.architecture.F_Latent): function f of the ODE of the latent dynamics\n",
    "        e1 (torch.tensor()): tensor of dimension [B, dim_latent], where B is the batch size and dim_latent the dimension of the latent space\n",
    "        dt (torch.Tensor): a tensor containing the dts used to advance each snapshot in time. It has dimensions [B, T-1], where B is the batch size and T is the length of the time series. it assumes each batch evolves accordingly to the same dts \n",
    "        mu (tc.tensor()): tensor of dimension [B, num_params] where B is the batch size and num_params the number of parameters of the system\n",
    "        k (int): stage of Runge-Kutta algorithm\n",
    "        RK (dict): dictionary with Butcher tablue for Runge-Kutta algorithms\n",
    "        ma_mi (list): list of lists of maximum and minima of fields and parameters\n",
    "        device (torch.device): device where the training and validation are done\n",
    "        time_dependence_in_f (bool):  if true, the function f depends on time as well.\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor(): tensor of dimension [B, dim_latent] which contains the latent vectors advanced in time from e1 of dt\n",
    "    \"\"\"    \n",
    "    # k=1 is Euler\n",
    "    ma_mi[2] = ma_mi[2].to(device)\n",
    "    ma_mi[3] = ma_mi[3].to(device)\n",
    "    mu = normalize_field_known_values_param(mu, ma_mi[2], ma_mi[3])\n",
    "    b = tc.zeros((k, e1.size(0), e1.size(1)) , device= device)\n",
    "    b[0, :,:] = f(e1, mu )\n",
    "    final_sum = f(e1, mu)*RK[str(k)][-1][1]\n",
    "\n",
    "    for i in range(k-1):\n",
    "        mu_in_time = mu.clone() #avoid in place operation which messes with backprop.\n",
    "        if time_dependence_in_f:\n",
    "            mu_in_time[:,-1] = mu_in_time[:,-1] +  RK[str(k)][i+1][0] * dt.squeeze(-1) \n",
    "        s = tc.zeros_like(e1, device = device)\n",
    "\n",
    "        for j in range(i+1):\n",
    "            s +=  b[j] * RK[str(k)][i+1][j+1]\n",
    "\n",
    "        b_new = f(e1 + dt * s, mu_in_time).unsqueeze(0).to(device)\n",
    "        b[i+1,:,:] = b_new\n",
    "\n",
    "        final_sum += b_new.squeeze(0) * RK[str(k)][-1][i+2]\n",
    "    e2 = e1 + final_sum * dt\n",
    "    return e2\n",
    "\n",
    "def predict_spatio_temporal_norm_param_in_latent_space(conv_encoder, f, conv_decoder, initial_cond, T, param, normalization, k, device, dim_input, ma_field, mi_field, ma_p,mi_p, field_dimension, time_dependence_in_f):\n",
    "    \n",
    "    predictions = initial_cond.clone().to(device)\n",
    "    initial_cond = normalize_field_known_values(initial_cond,ma_field,mi_field).to(device)\n",
    "\n",
    "    x_grid = np.shape(initial_cond)[-1]\n",
    "    y_grid = np.shape(initial_cond)[-2]\n",
    "    batch_num = initial_cond.size()[0]\n",
    "\n",
    "    if dim_input == 1:\n",
    "        latent = conv_encoder(initial_cond.reshape(batch_num , field_dimension[0], x_grid)).unsqueeze(1)\n",
    "    else:\n",
    "        latent = conv_encoder(initial_cond.reshape(batch_num , field_dimension[0], y_grid, x_grid)).unsqueeze(1)\n",
    "\n",
    "    for count, i in enumerate(T[1:]):\n",
    "        dt = tc.tensor(i-T[count]).expand(batch_num, 1).to(device)\n",
    "        latent_new = processor_First_Order(f, latent[:,-1,:], dt, param, k, RK, [ma_field,mi_field, ma_p, mi_p],device, time_dependence_in_f)\n",
    "        latent = tc.cat((latent, latent_new.unsqueeze(1)),dim = 1)\n",
    "\n",
    "        field_prediction = conv_decoder(latent_new).unsqueeze(1)\n",
    "        predictions = tc.cat((predictions, inverse_normalization_field(field_prediction,ma_field,mi_field, field_dimension[1])),dim = 1)\n",
    "    return predictions.squeeze(0).detach().cpu().numpy(), latent.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "def predict_spatio_temporal_norm_param_in_latent_space_for_time_inference(conv_encoder, f, conv_decoder, initial_cond, T, param, normalization, k, device, dim_input, ma_field, mi_field, ma_p,mi_p, field_dimension, time_dependence_in_f):\n",
    "    \n",
    "    initial_cond = normalize_field_known_values(initial_cond,ma_field,mi_field)\n",
    "\n",
    "    x_grid = np.shape(initial_cond)[-1]\n",
    "    y_grid = np.shape(initial_cond)[-2]\n",
    "    batch_num = initial_cond.size()[0]\n",
    "\n",
    "    if dim_input == 1:\n",
    "        latent = conv_encoder(initial_cond.reshape(batch_num , field_dimension[0], x_grid)).unsqueeze(1)\n",
    "    else:\n",
    "        latent = conv_encoder(initial_cond.reshape(batch_num , field_dimension[0], y_grid, x_grid)).unsqueeze(1)\n",
    "\n",
    "    for count, i in enumerate(T[1:]):\n",
    "        dt = tc.tensor(i-T[count]).expand(batch_num, 1).to(device)\n",
    "        latent_new = processor_First_Order(f, latent[:,-1,:], dt, param, k, RK, [ma_field,mi_field, ma_p, mi_p],device, time_dependence_in_f)\n",
    "        latent = tc.cat((latent, latent_new.unsqueeze(1)),dim = 1)\n",
    "    size_latent = latent.size()\n",
    "    latent = tc.reshape(latent,(size_latent[0]*size_latent[1],size_latent[2] ))\n",
    "    out = conv_decoder(latent)\n",
    "    if dim_input == 1:\n",
    "        out = tc.reshape(out,(batch_num, len(T),field_dimension[0],x_grid))\n",
    "    else:\n",
    "        out = tc.reshape(out,(batch_num, len(T),field_dimension[0], y_grid, x_grid))\n",
    "    predictions = inverse_normalization_field(out ,ma_field,mi_field, field_dimension[1])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def build_dataset_finer_time( T, testing_parameters, ic):\n",
    "    expected = []\n",
    "    for count, init in enumerate(ic):\n",
    "        out = []\n",
    "        for t in T:\n",
    "            result = advection(init, testing_parameters[count], t)\n",
    "            out.append(result)\n",
    "        expected.append(out)\n",
    "        \n",
    "    return expected\n",
    "\n",
    "def build_dataset_finer_time_molenkamp(testing, T, testing_parameters):\n",
    "    expected = []\n",
    "    a = np.linspace(-1,1,128)\n",
    "    b = np.linspace(1,-1,128)\n",
    "    X, Y = np.meshgrid(a, b)\n",
    "    with tc.no_grad():\n",
    "        for ic, _ in testing:\n",
    "            for count,_ in enumerate(ic.detach().cpu().numpy()):\n",
    "                expected.append([molenkeamp(X,Y, testing_parameters[count] , j) for j in T])\n",
    "    return expected\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd071fe6-de02-4ca6-aaa6-cca5ccf7fe48",
   "metadata": {},
   "source": [
    "# Set path to saved NNs models, path to data for testing and necessary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db450b94-a239-47b3-9245-8600b84edd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '../../datasets/burgers/Models/not_coupled/'\n",
    "data_generation_test = '../../../../../scratch/aalelonghi/benchmark/burgers_0.001/'\n",
    "\n",
    "directory_images = path_models+'/Images/'\n",
    "os.makedirs(directory_images, exist_ok=True)\n",
    "sys.path.append(path_models + '/scripts/src/')\n",
    "from architecture import *\n",
    "\n",
    "#set device\n",
    "device = tc.device(\"cuda:1\") if tc.cuda.is_available() else tc.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "#read file with normalization of inputs\n",
    "normalization = pd.read_csv(path_models+'/Normalization.csv')\n",
    "string_field = normalization['Field'][0].split(\"), 'Min': tensor(\")\n",
    "ma_field = tc.tensor([float(x) for x in string_field[0][16:-2].split(\",\")], device=device)\n",
    "mi_field = tc.tensor([float(x) for x in string_field[1][1:-3].split(\",\")], device = device)\n",
    "string_param = normalization['Param'][0].split(\"), 'Min': tensor(\")\n",
    "string_param = normalization['Param'][0].split(\", 'Min': tensor(\")\n",
    "ma_p = tc.tensor([float(x) for x in string_param[0][16:-2].split(\",\")], device=device)\n",
    "mi_p = tc.tensor([float(x) for x in string_param[1][1:-3].split(\",\")], device = device)\n",
    "\n",
    "print('maximum value field', ma_field)\n",
    "print('minimum value field', mi_field)\n",
    "print('maximum value parameters', ma_p)\n",
    "print('minimum value parameters', mi_p)\n",
    "\n",
    "initial_information = load_config(path_models + '/scripts/configs/initial_information.yaml')\n",
    "model_information = load_config(path_models + '/scripts/configs/model_information.yaml')\n",
    "print(initial_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8033a-f527-40de-8978-4b39ea779a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_information['filters_deco'].append(initial_information['dim_input'][0])\n",
    "n_halving = len(np.where(np.array(model_information['stride_enc'])==2)[0]) \n",
    "final_reduction = int(initial_information['side_size'] /(2**n_halving)) #final\n",
    "\n",
    "if initial_information['dim_input'][1] == 1:\n",
    "    model_information['input_output_dfnn'] = int(final_reduction * model_information['filters_enc'][-1] ) #dimension of the vector the final linear layer of the encoder receives\n",
    "elif initial_information['dim_input'][1] == 2:\n",
    "    model_information['input_output_dfnn'] = int(final_reduction**2 * model_information['filters_enc'][-1] ) #dimension of the vector the final linear layer of the encoder receives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c870e-fade-4067-acb4-d15b1e8011a3",
   "metadata": {},
   "source": [
    "# Load weights of the saved models and define specific settings of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69469fd5-d084-49fa-b0d2-ee3fdf91ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_encoder = Convolutional_Encoder(initial_information['dim_input'], model_information['kernel_enc'], model_information['filters_enc'], model_information['stride_enc'], model_information['input_output_dfnn'], model_information['latent_dim'], model_information['final_and_initial_activation'])\n",
    "f = F_Latent(model_information['parameter_information'], initial_information['dim_parameter'], model_information['latent_dim'], model_information['n_neurons_f'], model_information['n_layers_f'], model_information['n_FiLM_conditioning'])\n",
    "conv_decoder = Convolutional_Decoder(initial_information['dim_input'], model_information['kernel_deco'], model_information['filters_deco'], model_information['stride_dec'], model_information['latent_dim'], model_information['input_output_dfnn'], final_reduction, model_information['final_and_initial_activation'])\n",
    "\n",
    "checkpoint = tc.load(path_models+'/checkpoint/check.pt', map_location=device, weights_only=True)\n",
    "conv_encoder.load_state_dict(checkpoint['enco'])\n",
    "f.load_state_dict(checkpoint['f'])\n",
    "conv_decoder.load_state_dict(checkpoint['dec'])\n",
    "\n",
    "total_params_enc = sum(p.numel() for p in conv_encoder.parameters() if p.requires_grad)\n",
    "total_params_dec = sum(p.numel() for p in conv_decoder.parameters() if p.requires_grad)\n",
    "total_params_f = sum(p.numel() for p in f.parameters() if p.requires_grad)\n",
    "\n",
    "memory_in_mb = (total_params_enc+total_params_dec+total_params_f * 4) / (1024 ** 2)\n",
    "print(f\"Model memory: {memory_in_mb:.2f} MB\")\n",
    "\n",
    "print(f\"Total number of parameters enc: {total_params_enc}\")\n",
    "print(f\"Total number of parameters dec : {total_params_dec}\")\n",
    "print(f\"Total number of parameters input f: {total_params_f}\")\n",
    "print(f\"Total number of parameters: {total_params_enc+total_params_dec+total_params_f}\")\n",
    "\n",
    "conv_encoder.to(device)\n",
    "f.to(device)\n",
    "conv_decoder.to(device)\n",
    "\n",
    "conv_encoder.eval()\n",
    "f.eval()\n",
    "conv_decoder.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7ae37-9c5b-4ecf-bc25-cfd48ac2a001",
   "metadata": {},
   "source": [
    "# Define testing objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fc426-3a8a-4cfc-a0f4-6d1d72ef625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_time_serie = np.array(np.load(data_generation_test+\"/testing_output.npy\"),dtype=\"float32\") #should be of size [B,T,C,W,H]\n",
    "testing_parameters = np.array(np.load(data_generation_test+\"/testing_parameter.npy\"),dtype=\"float32\")\n",
    "testing_T = np.array(np.load(data_generation_test+\"/testing_T.npy\"),dtype=\"float32\")\n",
    "ic = np.array(np.load(data_generation_test+\"/testing_initial_conditions.npy\"),dtype=\"float32\")\n",
    "testing_T = np.arange(0,2.05,0.05,dtype=\"float32\")\n",
    "\n",
    "testing_time_serie_diff_time = np.load('../../../../../../../scratch/aalelonghi/benchmark/burgers_0.001/discretization_0.01/testing_output.npy')\n",
    "inference_T = np.float32(np.arange(0,2.01,0.01))\n",
    "\n",
    "#if needed, adjust the dimension of testing_time_serie\n",
    "testing_time_serie = testing_time_serie[:,:,None,:]\n",
    "testing_time_serie_diff_time = testing_time_serie_diff_time[:,:,None,:]\n",
    "\n",
    "print('testing_time_serie',np.shape(testing_time_serie ))\n",
    "print('testing_parameters',np.shape(testing_parameters ))\n",
    "print('ic',np.shape(ic ))\n",
    "print('testing_T',np.shape(testing_T ))\n",
    "print('testing_time_serie_diff_time',np.shape(testing_time_serie_diff_time ))\n",
    "print('inference_T',np.shape(inference_T ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d2bd7-1998-4934-85d3-60108ec29ca7",
   "metadata": {},
   "source": [
    "# Define some needed details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b2c97-c8f5-4fec-a3d5-2fb74aca1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = model_information['latent_dim'] #dimension of the latent space \n",
    "dim_field = initial_information['dim_input'] # first dimension is the channels of the solution field, second is the number of spatial dimensions\n",
    "K = 4 #runge kutta order\n",
    "\n",
    "RK = {\n",
    "'1' : tc.tensor([[0,0],[0,1]]),\n",
    "'2' : tc.tensor([[0,0,0],[1,1,0],[0, 1/2,1/2]]),\n",
    "'3' : tc.tensor([[0,0,0,0],[1/2,1/2,0,0],[1,-1,2,0],[0,1/6,2/3,1/6]]),\n",
    "'4' : tc.tensor([[0,0,0,0,0],[1/2,1/2,0,0,0],[1/2,0,1/2,0,0],[1,0,0,1,0],[0,1/6,1/3,1/3,1/6]])\n",
    "}\n",
    "time_dependence_in_f = False #if true, the function f of the latent space depends on time as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e03260-825e-4acd-bcf0-9fa0cb89f39e",
   "metadata": {},
   "source": [
    "# Prediction when Encoding and then Decoding the testing dataset using the **training** dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68fcd5-bfde-42a0-9f59-7d929eac39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensor_time_serie = normalize_field_known_values(tc.tensor(testing_time_serie, device=device),ma_field,mi_field)\n",
    "size = tensor_time_serie.size()\n",
    "if dim_field[1] == 1:\n",
    "    tensor_time_serie = tc.reshape(tensor_time_serie, (size[0]*size[1],size[2],size[3]))\n",
    "elif dim_field[1] == 2:\n",
    "    tensor_time_serie = tc.reshape(tensor_time_serie, (size[0]*size[1],size[2],size[3],size[4]))\n",
    "print(tensor_time_serie.size())\n",
    "\n",
    "with tc.no_grad():\n",
    "    mid_point_encoded_training = conv_encoder(tensor_time_serie)\n",
    "    mid_point_decoded = conv_decoder(mid_point_encoded_training)\n",
    "mid_point_encoded_training = tc.reshape(mid_point_encoded_training, (size[0],size[1],latent_dim)).detach().cpu().numpy()\n",
    "mid_point_decoded = inverse_normalization_field(mid_point_decoded,ma_field,mi_field, dim_field[1])\n",
    "if dim_field[1] == 1: \n",
    "    mid_point_decoded_training = tc.reshape(mid_point_decoded, (size[0],size[1],size[2],size[3])).detach().cpu().numpy()\n",
    "elif dim_field[1] == 2:\n",
    "    mid_point_decoded_training = tc.reshape(mid_point_decoded, (size[0],size[1],size[2],size[3],size[4])).detach().cpu().numpy() \n",
    "\n",
    "print('mid_point_decoded_training', np.shape(mid_point_decoded_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6653372-3155-4b39-b09f-ef2f542946dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = np.shape(mid_point_decoded_training)\n",
    "size2 = np.shape(testing_time_serie)\n",
    "print('mid_point_decoded_training',size1)\n",
    "print('testing_time_serie',size2)\n",
    "error = []\n",
    "for count, i in enumerate(mid_point_decoded_training):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        err = np.linalg.norm(i[j].flatten()-testing_time_serie[count][j].flatten())/np.linalg.norm(testing_time_serie[count][j].flatten())\n",
    "        error.append(err)\n",
    "err = np.mean(error)\n",
    "\n",
    "print('average nRMSE = ', err)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Datapoint in testing set')\n",
    "plt.ylabel('nRMSE') \n",
    "plt.title('Relative error of AutoEncoding across testing dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286eddc9-8422-4782-aa00-6f94bae0e75d",
   "metadata": {},
   "source": [
    "# Prediction when Encoding and then Decoding the testing dataset using the **testing** (smaller) dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c058a50-2671-4d1c-ba12-a3900b1203e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_time_serie = normalize_field_known_values(tc.tensor(testing_time_serie_diff_time, device=device),ma_field,mi_field)\n",
    "size = tensor_time_serie.size() #should be of size [B,T,C,W,H]\n",
    "if dim_field[1] == 1:\n",
    "    tensor_time_serie = tc.reshape(tensor_time_serie, (size[0]*size[1],size[2],size[3]))\n",
    "elif dim_field[1] == 2:\n",
    "    tensor_time_serie = tc.reshape(tensor_time_serie, (size[0]*size[1],size[2],size[3],size[4]))\n",
    "\n",
    "with tc.no_grad():\n",
    "    mid_point_encoded_inference = conv_encoder(tensor_time_serie)\n",
    "    mid_point_decoded = conv_decoder(mid_point_encoded_inference)\n",
    "mid_point_encoded_inference = tc.reshape(mid_point_encoded_inference, (size[0],size[1],latent_dim)).detach().cpu().numpy()\n",
    "mid_point_decoded = inverse_normalization_field(mid_point_decoded,ma_field,mi_field,dim_field[1])\n",
    "if dim_field[1] == 1: \n",
    "    mid_point_decoded_inference = tc.reshape(mid_point_decoded, (size[0],size[1],size[2],size[3])).detach().cpu().numpy()\n",
    "elif dim_field[1] == 2:\n",
    "    mid_point_decoded_inference = tc.reshape(mid_point_decoded, (size[0],size[1],size[2],size[3],size[4])).detach().cpu().numpy() \n",
    "\n",
    "print('mid_point_decoded_inference', np.shape(mid_point_decoded_inference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9aabd-2605-439b-b3f3-f5e0795235c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = np.shape(mid_point_decoded_inference)\n",
    "size2 = np.shape(testing_time_serie_diff_time)\n",
    "print('mid_point_decoded_inference',size1)\n",
    "print('testing_time_serie_diff_time',np.shape(testing_time_serie_diff_time))\n",
    "error = []\n",
    "for count, i in enumerate(mid_point_decoded_inference):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        err = np.linalg.norm(i[j].flatten()-testing_time_serie_diff_time[count][j].flatten())/np.linalg.norm(testing_time_serie_diff_time[count][j].flatten())\n",
    "        error.append(err)\n",
    "err = np.mean(error)\n",
    "print('average nRMSE = ', err)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Datapoint in testing set')\n",
    "plt.ylabel('nRMSE') \n",
    "plt.title('Relative error of AutoEncoding across testing dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdcae7-ded4-42ee-830f-fe5df5b3970c",
   "metadata": {},
   "source": [
    "# Obtain predictions when advancing in latent space at **training** dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af298d-8e58-4832-8501-85abfbe5ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_testing = CustomStarDataset(data_generation_test + '/testing_initial_conditions.npy', data_generation_test + '/testing_parameter.npy')\n",
    "testing = DataLoader(dataset_testing, batch_size = dataset_testing.__len__(), num_workers=0, shuffle=False,drop_last=True)\n",
    "\n",
    "prediction_array_full_dt_training = []\n",
    "prediction_array_reduced_dt_training = []\n",
    "with tc.no_grad():\n",
    "    for ic, p in testing:\n",
    "        ic = ic.unsqueeze(1) #should be of size [B,T,C,W,H]!\n",
    "        ic = ic.unsqueeze(1)\n",
    "        p = p.unsqueeze(-1) #should be of size [B,N_m]!, where N_m is the number of parameters\n",
    "        print(p.size())\n",
    "        print(ic.size())\n",
    "        ic = ic.to(device)\n",
    "        p = p.to(device)\n",
    "        t1 = time.time()\n",
    "        full, reduced = predict_spatio_temporal_norm_param_in_latent_space(conv_encoder, f, conv_decoder, ic, testing_T, p, normalization, K ,device, dim_field[1], ma_field, mi_field, ma_p, mi_p,dim_field, time_dependence_in_f)\n",
    "        t2 = time.time()\n",
    "        prediction_array_full_dt_training.append(full)\n",
    "        prediction_array_reduced_dt_training.append(reduced)\n",
    "        print(t2-t1)\n",
    "prediction_array_full_dt_training = prediction_array_full_dt_training[0]\n",
    "prediction_array_reduced_dt_training = prediction_array_reduced_dt_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f4be9-77bf-4127-aa55-eed293e25f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = np.shape(prediction_array_full_dt_training)\n",
    "size2 = np.shape(testing_time_serie)\n",
    "print('prediction_array_full_dt_training',size1)\n",
    "print('testing_time_serie',size2)\n",
    "error_training_dt_latent = []\n",
    "for count, i in enumerate(prediction_array_full_dt_training):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        err = np.linalg.norm(i[j].flatten()-testing_time_serie[count][j].flatten())/np.linalg.norm(testing_time_serie[count][j].flatten())\n",
    "        error_training_dt_latent.append(err)\n",
    "err = np.mean(error_training_dt_latent)\n",
    "print('average nRMSE = ', err)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Datapoint in testing set')\n",
    "plt.ylabel('nRMSE') \n",
    "plt.title('Relative error of prediction through time across testing dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d90c02-d9cf-44c7-a7fd-9e00070a38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE ERROR PER TIME STEP\n",
    "size1 = np.shape(prediction_array_full_dt_training)\n",
    "size2 = np.shape(testing_time_serie)\n",
    "Error1 = []\n",
    "above_error_treshold = 0\n",
    "for count, i in enumerate(prediction_array_full_dt_training):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        error = np.linalg.norm(i[j].flatten()-testing_time_serie[count][j].flatten())/np.linalg.norm(testing_time_serie[count][j].flatten())\n",
    "        if error > 10.0:\n",
    "            print(count)\n",
    "            print(testing_parameters[count])\n",
    "            above_error_treshold+=1\n",
    "            Error1.append(error)\n",
    "            \n",
    "        else:\n",
    "            Error1.append(error)\n",
    "relative_error_per_second1 = []\n",
    "Error1 = np.array(Error1)\n",
    "for i in range((len(testing_T)-1)):\n",
    "    relative_error_per_second1.append(np.sum(Error1[i:][::(len(testing_T)-1)])/len(np.where(Error1[i:][::(len(testing_T)-1)]!=0)[0]))\n",
    "print('Above error treshold',above_error_treshold )\n",
    "\n",
    "plt.plot(testing_T[1:], relative_error_per_second1, '*')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('nRMSE') \n",
    "plt.title('Average nRMSE per time step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873d9b1-9416-4c0f-90b1-4cb036f2ddf1",
   "metadata": {},
   "source": [
    "# Obtain predictions when advancing in latent space at **testing** (smaller) dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2642c-58cf-4383-a280-635e4a29da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_testing = CustomStarDataset(data_generation_test + '/testing_initial_conditions.npy', data_generation_test + '/testing_parameter.npy')\n",
    "testing = DataLoader(dataset_testing, batch_size = dataset_testing.__len__(), num_workers=0, shuffle=False,drop_last=True)\n",
    "prediction_array_full_dt_inference = []\n",
    "prediction_array_reduced_dt_inference = []\n",
    "with tc.no_grad():\n",
    "    for ic, p in testing:\n",
    "        ic = ic.unsqueeze(1) #should be of size [B,T,C,W,H]!\n",
    "        ic = ic.unsqueeze(1)\n",
    "        p = p.unsqueeze(-1) #should be of size [B,N_m]!, where N_m is the number of parameters\n",
    "        print(np.shape(ic))\n",
    "        ic = ic.to(device)\n",
    "        p = p.to(device)\n",
    "        full, reduced = predict_spatio_temporal_norm_param_in_latent_space(conv_encoder, f, conv_decoder, ic, inference_T, p, normalization, K ,device, dim_field[1], ma_field, mi_field, ma_p, mi_p, dim_field, time_dependence_in_f)\n",
    "        prediction_array_full_dt_inference.append(full)\n",
    "        prediction_array_reduced_dt_inference.append(reduced)\n",
    "prediction_array_full_dt_inference = prediction_array_full_dt_inference[0]\n",
    "prediction_array_reduced_dt_inference = prediction_array_reduced_dt_inference[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb42f3-a00e-42a7-ba63-bfa0b847aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = np.shape(prediction_array_full_dt_inference)\n",
    "size2 = np.shape(testing_time_serie_diff_time)\n",
    "print('prediction_array_full_dt_inference',size1)\n",
    "print('testing_time_serie_diff_time',size2)\n",
    "error_testing_dt_latent = []\n",
    "\n",
    "for count, i in enumerate(prediction_array_full_dt_inference):\n",
    "    for j in np.arange(1,size1[1]):\n",
    "        err = np.linalg.norm(i[j].flatten()-testing_time_serie_diff_time[count][j].flatten())/np.linalg.norm(testing_time_serie_diff_time[count][j].flatten())\n",
    "        error_testing_dt_latent.append(err)\n",
    "err2 = np.mean(error_testing_dt_latent)\n",
    "print('rel error' , err2)\n",
    "plt.plot(error_testing_dt_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677dc88-0c4e-4f0b-9d36-d2f932c9ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE ERROR PER TIME STEP\n",
    "\n",
    "size1 = np.shape(prediction_array_full_dt_inference)\n",
    "size2 = np.shape(testing_time_serie_diff_time)\n",
    "Error2 = []\n",
    "above_error_treshold = 0\n",
    "for count, i in enumerate(prediction_array_full_dt_inference):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        error = np.linalg.norm(i[j]-testing_time_serie_diff_time[count][j])/(np.linalg.norm(testing_time_serie_diff_time[count][j]))\n",
    "        if error > 10.0:\n",
    "            print(count)\n",
    "            print(testing_parameters[count])\n",
    "            above_error_treshold+=1\n",
    "            Error2.append(error)\n",
    "            \n",
    "        else:\n",
    "            Error2.append(error)\n",
    "relative_error_per_second2 = []\n",
    "Error2 = np.array(Error2)\n",
    "for i in range((len(inference_T)-1)):\n",
    "    relative_error_per_second2.append(np.sum(Error2[i:][::(len(inference_T)-1)])/len(np.where(Error2[i:][::(len(inference_T)-1)]!=0)[0]))\n",
    "\n",
    "print('Above error treshold',above_error_treshold )\n",
    "\n",
    "plt.plot(inference_T[1:], relative_error_per_second2, '*')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('nRMSE') \n",
    "plt.title('Average nRMSE per time step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8d056-dee1-4a7b-ab10-522816c9b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two errors over time when using different dt across the prediction\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(inference_T[1:],relative_error_per_second2,'o')\n",
    "plt.xlabel(r'$t$',fontsize = 12)\n",
    "plt.ylabel(r'$R_r^2(T)$',fontsize = 12)\n",
    "#plt.yscale('log')\n",
    "#plt.ylim([0.002,1])\n",
    "plt.grid()\n",
    "plt.savefig(directory_images+'error_over_time.png',dpi=200,facecolor='w',transparent=True,bbox_inches='tight')\n",
    "\n",
    "plt.plot(testing_T[1:],relative_error_per_second1,'o', label = 'dt = 0.05')\n",
    "plt.plot(inference_T[1:],relative_error_per_second2,'o', label = 'dt = 0.01')\n",
    "plt.xlabel('time',fontsize = 12)\n",
    "plt.ylabel('Average nRMSE',fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "#plt.yscale('log')\n",
    "#plt.ylim([0.002,1])\n",
    "plt.grid()\n",
    "#plt.ylim([0.0017,0.013])\n",
    "#plt.savefig(directory_images+'error_over_time_comparison.png',dpi=200,facecolor='w',transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c6764-48f1-41b2-8b66-536bf4248e30",
   "metadata": {},
   "source": [
    "# Error in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685a67c-2e7a-4025-b0e3-2fbbce5ef20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size1 = np.shape(prediction_array_reduced_dt_training)\n",
    "size2 = np.shape(mid_point_encoded_training)\n",
    "print('prediction_array_reduced_dt_training', size1)\n",
    "print('mid_point_encoded_training', size2)\n",
    "Error1_reduced = []\n",
    "above_error_treshold = 0\n",
    "for count, i in enumerate(prediction_array_reduced_dt_training):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        error = np.linalg.norm(i[j].flatten()-mid_point_encoded_training[count][j].flatten())/np.linalg.norm(mid_point_encoded_training[count][j].flatten())\n",
    "        if error > 10.0:\n",
    "            print(count)\n",
    "            print(testing_parameters[count])\n",
    "            above_error_treshold+=1\n",
    "            Error1_reduced.append(error)\n",
    "            \n",
    "        else:\n",
    "            Error1_reduced.append(error)\n",
    "relative_error_per_second1_reduced = []\n",
    "Error1_reduced = np.array(Error1_reduced)\n",
    "for i in range((len(testing_T)-1)):\n",
    "    relative_error_per_second1_reduced.append(np.sum(Error1_reduced[i:][::(len(testing_T)-1)])/len(np.where(Error1_reduced[i:][::(len(testing_T)-1)]!=0)[0]))\n",
    "size1 = np.shape(prediction_array_reduced_dt_inference)\n",
    "size2 = np.shape(mid_point_encoded_inference)\n",
    "print('prediction_array_reduced_dt_inference', size1)\n",
    "print('mid_point_encoded_inference', size2)\n",
    "Error2_reduced = []\n",
    "above_error_treshold = 0\n",
    "for count, i in enumerate(prediction_array_reduced_dt_inference):\n",
    "    for j in np.arange(1,size1[1],1):\n",
    "        error = np.linalg.norm(i[j].flatten()-mid_point_encoded_inference[count][j].flatten())/np.linalg.norm(mid_point_encoded_inference[count][j].flatten())\n",
    "        if error > 9:\n",
    "            print(count)\n",
    "            print(testing_parameters[count])\n",
    "            above_error_treshold+=1\n",
    "            Error2_reduced.append(error)\n",
    "            \n",
    "        else:\n",
    "            Error2_reduced.append(error)\n",
    "relative_error_per_second2_reduced = []\n",
    "Error2_reduced = np.array(Error2_reduced)\n",
    "for i in range((len(inference_T)-1)):\n",
    "    relative_error_per_second2_reduced.append(np.sum(Error2_reduced[i:][::(len(inference_T)-1)])/len(np.where(Error2_reduced[i:][::(len(inference_T)-1)]!=0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dbeec0-0b8c-45f8-ba45-998266c115b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(testing_T[1:],relative_error_per_second1_reduced,'o', label = 'dt = 0.05')\n",
    "plt.plot(inference_T[1:],relative_error_per_second2_reduced,'o', label = 'dt = 0.01')\n",
    "plt.xlabel(r'$t$',fontsize = 12)\n",
    "plt.ylabel('Average nRMSE in Reduced space',fontsize = 12)\n",
    "plt.legend(fontsize = 12)\n",
    "#plt.yscale('log')\n",
    "#plt.ylim([0.002,1])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b8513-6900-4d2c-8818-b8597dc7b868",
   "metadata": {},
   "source": [
    "# Look at the latent space evolution for specific samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c404591-7330-4a36-b956-55565ccd03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CONFRONT LATENT SPACE (with when solved only in latent training)\n",
    "plt.figure(figsize=(20,10))\n",
    "colors = plt.cm.get_cmap('tab20', 60) \n",
    "sample = 70\n",
    "for count, i  in enumerate(np.arange(0,30,1)):  \n",
    "    plt.plot(testing_T[0:],prediction_array_reduced_dt_training[sample][:,i],'+',markersize = 20,color = colors(count))\n",
    "    plt.plot(testing_T[0:],mid_point_encoded_training[sample][:,i],'o',color = colors(count))\n",
    "    plt.plot(inference_T,prediction_array_reduced_dt_inference[sample][:,i], \"--\",markersize = 20, color = colors(count))\n",
    "plt.grid()\n",
    "plt.xticks(testing_T)\n",
    "#plt.yscale('log')\n",
    "plt.scatter([], [], marker='o', color = 'k', label='True latent (encoding the true fields)') \n",
    "plt.scatter([], [], marker='+', color = 'k', label='Latent predicted on training dt (solving only in latent)') \n",
    "plt.scatter([], [], marker=0, color = 'k', label='Latent predicted on smaller dt (solving only in latent)') \n",
    "plt.xlabel('Time', fontsize = 18)\n",
    "plt.ylabel('Latent value', fontsize = 18)\n",
    "legend = plt.legend(fontsize = 16)\n",
    "#plt.savefig(directory_images+'/latent_varyingt_time_comparison_tot.png',dpi=200,facecolor='w',transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde8f45-62aa-4ee7-b0c5-92a0a21dba5a",
   "metadata": {},
   "source": [
    "# Inference time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6752e-68a5-4b4c-a4a4-49ff36e0c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much time\n",
    "#print(np.shape(ic))\n",
    "dataset_testing = CustomStarDataset(data_generation_test + '/testing_initial_conditions.npy', data_generation_test + '/testing_parameter.npy')\n",
    "testing = DataLoader(dataset_testing, batch_size = 64, num_workers=0, shuffle=True,drop_last=False)\n",
    "TIME = []\n",
    "prediction_array_full_dt_training = []\n",
    "prediction_array_reduced_dt_training = []\n",
    "for i in range(1000):\n",
    "    t = []\n",
    "    with tc.no_grad():\n",
    "        for ic, p in testing:\n",
    "            \n",
    "            ic = ic.unsqueeze(1) #should be of size [B,T,C,W,H]!\n",
    "            ic = ic.unsqueeze(1)\n",
    "            p = p.unsqueeze(-1)\n",
    "            ic = ic.to(device)\n",
    "            p = p.to(device)\n",
    "            start = tc.cuda.Event(enable_timing=True)\n",
    "            end = tc.cuda.Event(enable_timing=True)\n",
    "            start.record()\n",
    "            full = predict_spatio_temporal_norm_param_in_latent_space_for_time_inference(conv_encoder, f, conv_decoder, ic, testing_T, p, normalization, K ,device, dim_field[1], ma_field, mi_field, ma_p, mi_p,dim_field, time_dependence_in_f)\n",
    "            end.record()\n",
    "            tc.cuda.synchronize()\n",
    "            if i > 10:\n",
    "                t.append(start.elapsed_time(end))\n",
    "    TIME.append(np.sum(t))\n",
    "print('Average time', np.average(TIME))\n",
    "print('STD time' , np.std(TIME))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (artu)",
   "language": "python",
   "name": "artu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
